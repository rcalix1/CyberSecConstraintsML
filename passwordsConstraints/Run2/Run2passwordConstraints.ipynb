{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ea08f9",
   "metadata": {},
   "source": [
    "\n",
    "## Passwords Auditor with contraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcab9906",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## !pip install zxcvbn\n",
    "## !pip install password-strength\n",
    "## !pip install passlib\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf283c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from zxcvbn import zxcvbn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81cb1605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "VOCAB = list(string.ascii_letters + string.digits + \"!@#$%^&*\")\n",
    "V     = len(VOCAB)\n",
    "V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5495c3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([70])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "MASK_UPPER = torch.tensor([c in string.ascii_uppercase for c in VOCAB]).float()\n",
    "MASK_LOWER = torch.tensor([c in string.ascii_lowercase for c in VOCAB]).float()\n",
    "MASK_DIGIT = torch.tensor([c in string.digits          for c in VOCAB]).float()\n",
    "MASK_SPEC  = torch.tensor([c in \"!@#$%^&*\"             for c in VOCAB]).float()\n",
    "\n",
    "print(MASK_SPEC.shape)\n",
    "\n",
    "MASK_SPEC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d9d3ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TinyDecoder3(nn.Module):\n",
    "    \n",
    "    def __init__(self, z_dim=128, T=12, V=V):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.V = V\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, T * V)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        logits = self.net(z)                  # [B, T*V]\n",
    "        \n",
    "        return logits.view(z.size(0), self.T, self.V)  # [B, T, V]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b09b5016",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from password_strength import PasswordStats\n",
    "\n",
    "def score_with_password_strength(passwords):\n",
    "    stats = [PasswordStats(pw) for pw in passwords]\n",
    "    return {\n",
    "        \"average_strength\": sum(s.strength() for s in stats) / len(stats),\n",
    "        \"weak%\": sum(s.strength() < 0.3 for s in stats) / len(stats) * 100,\n",
    "        \"strong%\": sum(s.strength() > 0.7 for s in stats) / len(stats) * 100\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f05e0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "def estimate_entropy(passwd):\n",
    "    charset_size = 0\n",
    "    if any(c.islower() for c in passwd): charset_size += 26\n",
    "    if any(c.isupper() for c in passwd): charset_size += 26\n",
    "    if any(c.isdigit() for c in passwd): charset_size += 10\n",
    "    if any(c in \"!@#$%^&*()-_=+[{]};:'\\\",<.>/?\\\\|\" for c in passwd): charset_size += 32\n",
    "    if charset_size == 0: charset_size = 1\n",
    "    return len(passwd) * math.log2(charset_size)\n",
    "\n",
    "def average_entropy(passwords):\n",
    "    return sum(estimate_entropy(p) for p in passwords) / len(passwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42faf9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "def estimate_entropy(password):\n",
    "    charset_size = 0\n",
    "    if any(c.islower() for c in password): charset_size += 26\n",
    "    if any(c.isupper() for c in password): charset_size += 26\n",
    "    if any(c.isdigit() for c in password): charset_size += 10\n",
    "    if any(c in \"!@#$%^&*()-_=+[]{};:'\\\",.<>/?\\\\|\" for c in password): charset_size += 32\n",
    "    return len(password) * math.log2(charset_size or 1)\n",
    "\n",
    "def entropy_stats(passwords):\n",
    "    entropies = [estimate_entropy(pw) for pw in passwords]\n",
    "    return {\n",
    "        \"avg_entropy_bits\": sum(entropies) / len(entropies),\n",
    "        \"min\": min(entropies),\n",
    "        \"max\": max(entropies)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda15c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b2e380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24de6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TinyDecoder(nn.Module):\n",
    "    def __init__(self, z_dim=128, T=12, V=V):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.V = V\n",
    "        self.linear = nn.Linear(z_dim, T * V)\n",
    "\n",
    "    def forward(self, z):\n",
    "        logits = self.linear(z)                      # [B, T*V]\n",
    "        return logits.view(z.size(0), self.T, self.V)  # [B, T, V]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63a428e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def st_gumbel_softmax(logits, tau):\n",
    "    \n",
    "    eps = 1e-9\n",
    "    \n",
    "    g = -torch.log(-torch.log(torch.rand_like(logits) + eps) + eps)\n",
    "    \n",
    "    y_soft = F.softmax((logits + g) / tau, dim=-1)          # [B, T, V]\n",
    "    \n",
    "    y_hard = F.one_hot(\n",
    "                 y_soft.argmax(-1), \n",
    "                 y_soft.size(-1)\n",
    "    ).float()\n",
    "    \n",
    "    return y_hard + (y_soft - y_soft.detach())              # hard forward, soft grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f36081a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def class_present(p_pos):\n",
    "    \n",
    "    # p_pos: [B, T] probability per position of being in the class\n",
    "    \n",
    "    return 1.0 - torch.prod(1.0 - p_pos + 1e-6, dim=1)      # [B]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2e6a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def entropy_bits_per_string(y_probs):\n",
    "    # y_probs: [B, T, V], probs per token\n",
    "    p = y_probs.clamp_min(1e-9)\n",
    "    H_t = -(p * p.log()).sum(dim=-1)                         # nats, [B, T]\n",
    "    H = H_t.mean(dim=1)                                      # [B]\n",
    "    return H / torch.log(torch.tensor(2.0))                  # bits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a648053",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Decode one-hot/probabilities to strings ---\n",
    "\n",
    "def decode(y_probs):\n",
    "    idx = y_probs.argmax(dim=-1).cpu()                       # [B, T]\n",
    "    out = []\n",
    "    for row in idx.tolist():\n",
    "        out.append(\"\".join(VOCAB[i] for i in row))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3b3d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_passwords(batch=16, steps=300, T=12, H_min_bits=3.0, seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    model = TinyDecoder(T=T)\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False  # decoder is fixed\n",
    "\n",
    "    # ‚öôÔ∏è Weak seeds\n",
    "    weak = [\n",
    "        \"password\", \"qwerty\", \"letmein\", \"admin\",\n",
    "        \"welcome\", \"123456\", \"iloveyou\", \"guest\",\n",
    "        \"hello123\", \"abc123\", \"monkey\", \"test\",\n",
    "        \"summer\", \"dragon\", \"football\", \"name\"\n",
    "    ][:batch]\n",
    "    weak = [pw[:T].ljust(T, \"a\") for pw in weak]\n",
    "\n",
    "    # üî§ One-hot-style logit init\n",
    "    z_init = torch.full((batch, T, V), -6.0)\n",
    "    for b, pw in enumerate(weak):\n",
    "        for t, c in enumerate(pw):\n",
    "            if c in VOCAB:\n",
    "                z_init[b, t, VOCAB.index(c)] = 6.0\n",
    "\n",
    "    z = z_init.clone().detach().requires_grad_(True)\n",
    "    opt = torch.optim.Adam([z], lr=0.05)\n",
    "\n",
    "    for step in range(steps):\n",
    "        tau = max(0.8 - 0.003 * step, 0.2)\n",
    "        y_probs = F.softmax(z / tau, dim=-1)\n",
    "\n",
    "        # üîç Check class coverage\n",
    "        pU = (y_probs * MASK_UPPER).sum(dim=-1)\n",
    "        pL = (y_probs * MASK_LOWER).sum(dim=-1)\n",
    "        pD = (y_probs * MASK_DIGIT).sum(dim=-1)\n",
    "        pS = (y_probs * MASK_SPEC ).sum(dim=-1)\n",
    "\n",
    "        class_loss = (\n",
    "            0*F.relu(1.0 - class_present(pU)).mean() +\n",
    "            F.relu(1.0 - class_present(pL)).mean() +\n",
    "            F.relu(1.0 - class_present(pD)).mean() +\n",
    "            F.relu(1.0 - class_present(pS)).mean()\n",
    "        )\n",
    "\n",
    "        # üìà Entropy enforcement\n",
    "        H_bits = entropy_bits_per_string(y_probs)\n",
    "        entropy_loss = F.relu(H_min_bits - H_bits).mean()\n",
    "\n",
    "        # üéØ Final loss ‚Äî no divergence penalty\n",
    "        loss = class_loss + entropy_loss\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return decode(y_probs.detach())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b80d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_passwords_maybe(batch=16, steps=200, T=12, H_min_bits=3.0, seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    model = TinyDecoder(T=T)\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False  # freeze decoder\n",
    "\n",
    "    # ‚úÖ Define weak initial passwords\n",
    "    weak = [\n",
    "        \"password\", \"qwerty\", \"letmein\", \"admin\",\n",
    "        \"welcome\", \"123456\", \"iloveyou\", \"guest\",\n",
    "        \"hello123\", \"abc123\", \"monkey\", \"test\",\n",
    "        \"summer\", \"dragon\", \"football\", \"name\"\n",
    "    ][:batch]\n",
    "    weak = [pw[:T].ljust(T, \"a\") for pw in weak]\n",
    "\n",
    "    # ‚úÖ Create z_init based on those weak passwords\n",
    "    z_init = torch.full((batch, T, V), -6.0)  # low everywhere\n",
    "    for b, pw in enumerate(weak):\n",
    "        for t, c in enumerate(pw):\n",
    "            if c in VOCAB:\n",
    "                z_init[b, t, VOCAB.index(c)] = 6.0  # high where char matches\n",
    "\n",
    "    z = z_init.clone().detach().requires_grad_(True)\n",
    "\n",
    "    opt = torch.optim.Adam([z], lr=0.05)\n",
    "    y_probs = None\n",
    "\n",
    "    for t in range(steps):\n",
    "        tau = max(0.8 - 0.003 * t, 0.2)\n",
    "        logits = z\n",
    "        y_probs = F.softmax(logits / tau, dim=-1)  # <-- replaced Gumbel\n",
    "\n",
    "        # Char class presence\n",
    "        pU = (y_probs * MASK_UPPER).sum(dim=-1)\n",
    "        pL = (y_probs * MASK_LOWER).sum(dim=-1)\n",
    "        pD = (y_probs * MASK_DIGIT).sum(dim=-1)\n",
    "        pS = (y_probs * MASK_SPEC ).sum(dim=-1)\n",
    "\n",
    "        need_upper = F.relu(1.0 - class_present(pU)).mean()\n",
    "        need_lower = F.relu(1.0 - class_present(pL)).mean()\n",
    "        need_digit = F.relu(1.0 - class_present(pD)).mean()\n",
    "        need_spec  = F.relu(1.0 - class_present(pS)).mean()\n",
    "        class_loss = need_upper + need_lower + need_digit + need_spec\n",
    "\n",
    "        init_soft = F.softmax(z_init / tau, dim=-1).detach()\n",
    "        change_penalty = (y_probs - init_soft).abs().sum() / batch\n",
    "\n",
    "        # Optional entropy constraint\n",
    "        H_bits = entropy_bits_per_string(y_probs)\n",
    "        entropy_loss = F.relu(H_min_bits - H_bits).mean()\n",
    "\n",
    "        # Final loss\n",
    "        loss = class_loss + entropy_loss ## + 0.1 * change_penalty\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return decode(y_probs.detach())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844f0d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c324e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_passwords800(batch=16, steps=200, T=12, H_min_bits=3.0, seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    model = TinyDecoder(T=T)\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False  # freeze decoder\n",
    "\n",
    "    # ‚úÖ Define weak initial passwords\n",
    "    weak = [\n",
    "        \"password\", \"qwerty\", \"letmein\", \"admin\",\n",
    "        \"welcome\", \"123456\", \"iloveyou\", \"guest\",\n",
    "        \"hello123\", \"abc123\", \"monkey\", \"test\",\n",
    "        \"summer\", \"dragon\", \"football\", \"name\"\n",
    "    ][:batch]\n",
    "    weak = [pw[:T].ljust(T, \"a\") for pw in weak]\n",
    "\n",
    "    # ‚úÖ Create z_init based on those weak passwords\n",
    "    z_init = torch.full((batch, T, V), -6.0)  # low everywhere\n",
    "    for b, pw in enumerate(weak):\n",
    "        for t, c in enumerate(pw):\n",
    "            if c in VOCAB:\n",
    "                z_init[b, t, VOCAB.index(c)] = 6.0  # high where char matches\n",
    "\n",
    "    z = z_init.clone().detach().requires_grad_(True)\n",
    "\n",
    "    opt = torch.optim.Adam([z], lr=0.05)\n",
    "    y_probs = None\n",
    "\n",
    "    for t in range(steps):\n",
    "        tau = max(0.8 - 0.003 * t, 0.2)\n",
    "        logits = z\n",
    "        y_probs = st_gumbel_softmax(logits, tau)  # [B, T, V]\n",
    "\n",
    "        # Char class presence\n",
    "        pU = (y_probs * MASK_UPPER).sum(dim=-1)\n",
    "        pL = (y_probs * MASK_LOWER).sum(dim=-1)\n",
    "        pD = (y_probs * MASK_DIGIT).sum(dim=-1)\n",
    "        pS = (y_probs * MASK_SPEC ).sum(dim=-1)\n",
    "\n",
    "        need_upper = F.relu(1.0 - class_present(pU)).mean()\n",
    "        need_lower = F.relu(1.0 - class_present(pL)).mean()\n",
    "        need_digit = F.relu(1.0 - class_present(pD)).mean()\n",
    "        need_spec  = F.relu(1.0 - class_present(pS)).mean()\n",
    "        class_loss = need_upper + need_lower + need_digit + need_spec\n",
    "\n",
    "       \n",
    "        init_soft = F.softmax(z_init, dim=-1).detach()  # [B, T, V]\n",
    "        change_penalty = (y_probs - init_soft).abs().sum() / batch\n",
    "\n",
    "        # Optional entropy constraint\n",
    "        H_bits = entropy_bits_per_string(y_probs)\n",
    "        entropy_loss = F.relu(H_min_bits - H_bits).mean()\n",
    "\n",
    "        # Final loss\n",
    "        loss = class_loss + entropy_loss + 0.1 * change_penalty\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return decode(y_probs.detach())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c0fc7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_passwords23(batch=16, steps=200, T=12, H_min_bits=3.0, seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    model = TinyDecoder(T=T)\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False                              # freeze decoder (we only optimize z)\n",
    "\n",
    "    ## z = torch.randn(batch, 70, requires_grad=True)\n",
    "    z = torch.randn(batch, T, V, requires_grad=True)\n",
    "\n",
    "    \n",
    "    opt = torch.optim.Adam([z], lr=0.05)\n",
    "    y_probs = None\n",
    "\n",
    "    for t in range(steps):\n",
    "        tau = max(0.8 - 0.003 * t, 0.2)\n",
    "\n",
    "        logits = z     ## model(z)                                    # [B, T, V]\n",
    "        \n",
    "        y_probs = st_gumbel_softmax(logits, tau)             # [B, T, V]\n",
    "\n",
    "        pU = (y_probs * MASK_UPPER).sum(dim=-1)              # [B, T]\n",
    "        pL = (y_probs * MASK_LOWER).sum(dim=-1)\n",
    "        pD = (y_probs * MASK_DIGIT).sum(dim=-1)\n",
    "        pS = (y_probs * MASK_SPEC ).sum(dim=-1)\n",
    "\n",
    "        need_upper = F.relu(1.0 - class_present(pU)).mean()\n",
    "        need_lower = F.relu(1.0 - class_present(pL)).mean()\n",
    "        need_digit = F.relu(1.0 - class_present(pD)).mean()\n",
    "        need_spec  = F.relu(1.0 - class_present(pS)).mean()\n",
    "        \n",
    "        class_loss = need_upper + need_lower + need_digit + need_spec\n",
    "\n",
    "        H_bits       = entropy_bits_per_string(  y_probs  )            # [B]\n",
    "        entropy_loss = F.relu(H_min_bits - H_bits).mean()\n",
    "\n",
    "        loss = class_loss + entropy_loss\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return decode(  y_probs.detach()  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84affbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_passwords(password_list):\n",
    "    \"\"\"\n",
    "    Takes a list of passwords and returns:\n",
    "    - average score (0 to 4)\n",
    "    - score distribution\n",
    "    - crack time estimates\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    crack_times = []\n",
    "\n",
    "    for pw in password_list:\n",
    "        result = zxcvbn(pw)\n",
    "        scores.append(result['score'])\n",
    "        crack_times.append(result['crack_times_seconds']['offline_fast_hashing_1e10_per_second'])\n",
    "\n",
    "    avg_score = sum(scores) / len(scores)\n",
    "    score_distribution = {\n",
    "        score: scores.count(score) for score in range(5)\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'average_score': avg_score,\n",
    "        'score_distribution': score_distribution,\n",
    "        'avg_crack_time_secs': sum(crack_times) / len(crack_times)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d702ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3afbf1b9",
   "metadata": {},
   "source": [
    "\n",
    "## More mask constraints \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec19718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_passwords = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00f6d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "constraintsGeneratedPasswords = generate_passwords(batch=num_passwords, steps=2000, T=12, H_min_bits=3.0)\n",
    "\n",
    "## print(\"Sample:\", constraintsGeneratedPasswords )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "071b1f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!aa0!00!!!!\n",
      "0000aa!!!!!!\n",
      "00a0000!!!!!\n",
      "!0a0a!!!!!!!\n",
      "0000!a0!!!!!\n",
      "!!!000bbbbbb\n",
      "00!a00!a!!!!\n",
      "!a0aa0000000\n",
      "!a!!!000bbbb\n",
      "ba!000bbbbbb\n",
      "0!000a!!!!!!\n",
      "a0aa!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "for pass_generated in constraintsGeneratedPasswords[:12]:\n",
    "    print(pass_generated)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6436201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = evaluate_passwords(constraintsGeneratedPasswords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "692e3bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 0.0419921875\n",
      "Score distribution: {0: 1008, 1: 0, 2: 6, 3: 9, 4: 1}\n",
      "Average crack time (seconds): 0.00122523792578125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Average score:\", result['average_score'])\n",
    "print(\"Score distribution:\", result['score_distribution'])\n",
    "print(\"Average crack time (seconds):\", result['avg_crack_time_secs'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca703fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'average_strength': 0.003410087888529521, 'weak%': 100.0, 'strong%': 0.0}\n",
      "60.20389928273444\n",
      "{'avg_entropy_bits': 60.20389928273444, 'min': 60.0, 'max': 73.04955409500407}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pw = constraintsGeneratedPasswords\n",
    "\n",
    "print(score_with_password_strength(pw))\n",
    "print(average_entropy(pw))\n",
    "print(entropy_stats(pw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473e8439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b9467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187bbea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3c952a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115dec07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a41e2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e6d170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb35ba8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5145c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562fe452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecd8d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea937c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f610f889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62011a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01622478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bcd1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
